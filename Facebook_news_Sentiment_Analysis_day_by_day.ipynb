{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65224bc2",
   "metadata": {},
   "source": [
    "### WE ARE READING NEWS BY USING GOOGLE NEWS API TO CALCULATE THE PRICES OF FACEBOOK MARKET BY ANALYZING THE TEXT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e6e5558",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyspellchecker\n",
    "#!pip install regex\n",
    "#!conda install -c anaconda nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b3f3965-9094-4df7-a249-b64137718316",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zigron\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Zigron\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\Users\\Zigron\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\\n%s\" %\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "from urllib.request import urlopen\n",
    "from urllib.request import Request\n",
    "from GoogleNews import GoogleNews\n",
    "#from pygooglenews import GoogleNews\n",
    "from spellchecker import SpellChecker\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from spellchecker import SpellChecker\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fe1e05",
   "metadata": {},
   "source": [
    "### Intialize all object that are to be the part of text cleaning and calculating sentiment score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6eb182ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "spell = SpellChecker()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "sid_obj = SentimentIntensityAnalyzer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba4e280-b1c2-4a13-9cb6-9ef1a01778d2",
   "metadata": {},
   "source": [
    "## Google News Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "286c35d4-bf9d-452b-afdc-0295f4a0b514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def google_news(searches, lang='en', period='1d'):\n",
    "    final_df = pd.DataFrame(columns=['title', 'datetime'])\n",
    "    for search in searches:\n",
    "        googlenews = GoogleNews(lang=lang,period=period)\n",
    "        googlenews.get_news(search)\n",
    "        scraped_news = pd.DataFrame(googlenews.results())\n",
    "        scraped_news = scraped_news.drop(['desc', 'link', 'date','img', 'media', 'site'], axis=1)\n",
    "        final_df = final_df.append(scraped_news)\n",
    "    return scraped_news, googlenews, final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89574562-6518-43b4-b8ed-435891e1d8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, news, scraped_news = google_news(['Facebook', 'Facebook Stock Price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af9d4fa4-95d7-4aeb-a00d-833eb17254cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Leaving Facebook? Easier said than done</td>\n",
       "      <td>2021-11-11 16:08:50.929485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The types of Facebook ads you see could change...</td>\n",
       "      <td>2021-11-11 02:08:50.929485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>On Hate In India, Facebook's Surprise Findings</td>\n",
       "      <td>2021-11-11 21:08:50.929485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Facebook Whistleblower Frances Haugen 'Extreme...</td>\n",
       "      <td>2021-11-11 15:08:50.929485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Facebook's work app Workplace to integrate wit...</td>\n",
       "      <td>2021-11-11 11:08:50.929485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0            Leaving Facebook? Easier said than done   \n",
       "1  The types of Facebook ads you see could change...   \n",
       "2     On Hate In India, Facebook's Surprise Findings   \n",
       "3  Facebook Whistleblower Frances Haugen 'Extreme...   \n",
       "4  Facebook's work app Workplace to integrate wit...   \n",
       "\n",
       "                    datetime  \n",
       "0 2021-11-11 16:08:50.929485  \n",
       "1 2021-11-11 02:08:50.929485  \n",
       "2 2021-11-11 21:08:50.929485  \n",
       "3 2021-11-11 15:08:50.929485  \n",
       "4 2021-11-11 11:08:50.929485  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scraped_news.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880918b1-f05e-4f4d-9b6e-72e0c8bff85e",
   "metadata": {},
   "source": [
    "## FinViz Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b55315c-1715-4e22-940c-ca47a1e3f483",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finviz_scraper(tickers, n):\n",
    "    finviz_url = 'https://finviz.com/quote.ashx?t='\n",
    "    news_tables = {}\n",
    "    for ticker in tickers:\n",
    "        url = finviz_url + ticker\n",
    "        req = Request(url=url,headers={'user-agent': 'my-app/0.0.1'}) \n",
    "        resp = urlopen(req)    \n",
    "        html = BeautifulSoup(resp, features=\"lxml\")\n",
    "        news_table = html.find(id='news-table')\n",
    "        news_tables[ticker] = news_table\n",
    "        \n",
    "    try:\n",
    "        for ticker in tickers:\n",
    "            df = news_tables[ticker]\n",
    "            df_tr = df.findAll('tr')\n",
    "\n",
    "            for i, table_row in enumerate(df_tr):\n",
    "                a_text = table_row.a.text\n",
    "                td_text = table_row.td.text\n",
    "                td_text = td_text.strip()\n",
    "                if i == n-1:\n",
    "                    break\n",
    "    except KeyError:\n",
    "        pass\n",
    "    \n",
    "    parsed_news = []\n",
    "    for file_name, news_table in news_tables.items():\n",
    "        for x in news_table.findAll('tr'):\n",
    "            text = x.a.get_text() \n",
    "            date_scrape = x.td.text.split()\n",
    "\n",
    "            if len(date_scrape) == 1:\n",
    "                time = date_scrape[0]\n",
    "\n",
    "            else:\n",
    "                date = date_scrape[0]\n",
    "                time = date_scrape[1]\n",
    "\n",
    "            ticker = file_name.split('_')[0]\n",
    "\n",
    "            parsed_news.append([ticker, date, time, text])\n",
    "    columns = ['Ticker', 'Date', 'Time', 'Headline']\n",
    "    news = pd.DataFrame(parsed_news, columns=columns)\n",
    "    news['DateTime'] = news['Date'] + ' ' + news['Time']\n",
    "    news = news.drop(['Date', 'Time'], axis=1)\n",
    "    news['DateTime'] = pd.to_datetime(news['DateTime'])\n",
    "    return news,news_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e34adfe7-2638-4e2b-83b3-aae72c6b8cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_news, fin_table = finviz_scraper(['FB'], n=10)\n",
    "fin_news['DateTime'] = fin_news['DateTime'].dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bd6f51-96f8-44dc-8369-dfe6ccf39577",
   "metadata": {},
   "source": [
    "### Merging Finviz and Google News Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83fcac30-9554-4fa7-a75e-ee265fa47eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_news['datetime'] = scraped_news['datetime'].dt.date\n",
    "scraped_news.dropna(inplace=True)\n",
    "scraped_news['Ticker'] = 'FB'\n",
    "\n",
    "fin_news.columns = ['ticker', 'headline', 'datetime']\n",
    "scraped_news.columns = ['headline', 'datetime', 'ticker']\n",
    "fin_news = fin_news[['headline', 'datetime', 'ticker']]\n",
    "full_df = fin_news.append(scraped_news)\n",
    "full_df.sort_values(by='datetime', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc10f66a",
   "metadata": {},
   "source": [
    "### HERE WE CONCATENATE THE DATASET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dcab03a-efa3-4b61-8dbb-55c64b465b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>datetime</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>FB Investor Alert: Shareholder Lawsuit Filed</td>\n",
       "      <td>2021-11-07</td>\n",
       "      <td>FB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>AMD partners with Meta, seeks to 'advance semi...</td>\n",
       "      <td>2021-11-08</td>\n",
       "      <td>FB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>AMD Stock Is Surging. Facebooks Parent Is Usin...</td>\n",
       "      <td>2021-11-08</td>\n",
       "      <td>FB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>IMPORTANT REMINDER: FACEBOOK, INC. (NASDAQ:FB)...</td>\n",
       "      <td>2021-11-08</td>\n",
       "      <td>FB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Why AMD Stock Surged to a New All-Time High Today</td>\n",
       "      <td>2021-11-08</td>\n",
       "      <td>FB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             headline    datetime ticker\n",
       "99       FB Investor Alert: Shareholder Lawsuit Filed  2021-11-07     FB\n",
       "80  AMD partners with Meta, seeks to 'advance semi...  2021-11-08     FB\n",
       "68  AMD Stock Is Surging. Facebooks Parent Is Usin...  2021-11-08     FB\n",
       "69  IMPORTANT REMINDER: FACEBOOK, INC. (NASDAQ:FB)...  2021-11-08     FB\n",
       "70  Why AMD Stock Surged to a New All-Time High Today  2021-11-08     FB"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5387e887",
   "metadata": {},
   "source": [
    "###  We have to Check how many rows and columns in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b40edeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBER OF ROWS : 230  NUMBER OF COLUMNS : 3\n"
     ]
    }
   ],
   "source": [
    "rows,columns=full_df.shape\n",
    "print('NUMBER OF ROWS :',rows,'','NUMBER OF COLUMNS :',columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe8db35",
   "metadata": {},
   "source": [
    "###  This function is used to remove the redundant of the values present in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89795bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_redundant_rows(FacebookData) :\n",
    "    return FacebookData.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a63088c",
   "metadata": {},
   "source": [
    "### Cleaning the text by removing url hashtags mentions puntuation and extra whitespaces from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7f1ec23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_text(sentence) :\n",
    "    sentence = sentence.lower()                    # lower text\n",
    "    sentence = re.sub('http\\S+\\s*', '', sentence)  # remove URLs\n",
    "    sentence = re.sub('\\W+', ' ', sentence)        # remove commas \n",
    "    sentence= re.sub('RT|cc', '', sentence)  # remove RT and cc\n",
    "    sentence = re.sub('#\\S+', '', sentence)  # remove hashtags\n",
    "    sentence = re.sub('@\\S+', '', sentence)  # remove mentions\n",
    "    sentence = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"), '',sentence)  # remove punctuations\n",
    "    sentence = re.sub('\\s+', ' ', sentence)  # remove extra whitespace\n",
    "    sentence = re.sub(r'[0-9]', '', sentence) # remove digits from text\n",
    "    return sentence\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a277997",
   "metadata": {},
   "source": [
    "### Tokenization is used to remove the useless words thats are not much worthy for our sentiment analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3ae7a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization_lemmatize_stopwording(sentence):\n",
    "    sentence = word_tokenize(sentence)\n",
    "    sentence = [lemmatizer.lemmatize(i) for i in sentence if not i in stop_words]\n",
    "    sentence = ' '.join(sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddcb83a",
   "metadata": {},
   "source": [
    "### I am using vader library to calculate sentiment score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "497a7801",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_scores(sentence):\n",
    "    # Create a SentimentIntensityAnalyzer object.\n",
    "    sid_obj = SentimentIntensityAnalyzer()\n",
    "    # polarity_scores method of SentimentIntensityAnalyzer\n",
    "    # object gives a sentiment dictionary.\n",
    "    # which contains pos, neg, neu, and compound scores.\n",
    "    sentiment_dict = sid_obj.polarity_scores(sentence)\n",
    "\n",
    "    # decide sentiment as positive, negative and neutral\n",
    "    if sentiment_dict['compound'] >= 0.05 :\n",
    "        return \"Positive\"\n",
    "    elif sentiment_dict['compound'] <= - 0.05 :\n",
    "        return \"Negative\"\n",
    "    else :\n",
    "        return \"Neutral\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99f3514",
   "metadata": {},
   "source": [
    "### Here we can predict the price based on sentiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c513726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_prediction(sentiment) :\n",
    "    if sentiment=='Positive' :\n",
    "        return 'Increase'\n",
    "    elif sentiment=='Negative' :\n",
    "        return 'Negative'\n",
    "    else :\n",
    "        return 'Nochange'\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd4fa66",
   "metadata": {},
   "source": [
    "### Convert list into DateFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a61f568",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_frame(list_) :\n",
    "    return pd.DataFrame(list_, columns=['Date', 'Text','Textsentiment','Priceprediction'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bb02fc",
   "metadata": {},
   "source": [
    "### DAY BY DAY  Text SENTIMENT  ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0cd01ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_average_score(Dataframe_) :\n",
    "    sc=pd.pivot_table(Dataframe_,index=['Date'],\n",
    "                          columns=['Textsentiment'],aggfunc='count',fill_value=0)\n",
    "    return sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c081573",
   "metadata": {},
   "source": [
    "### DAY BY DAY  Price SENTIMENT  ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2fd1ef00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calculate_price_analysis_dy_by_day (pivot_table) :\n",
    "    Dataframe=pivot_table['Priceprediction'].reset_index()\n",
    "    for row in  Dataframe.itertuples(index = True, name ='Pandas'):\n",
    "        print(getattr(row, \"Date\"))\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343ed7db",
   "metadata": {},
   "source": [
    "### Text Preprocessing is the technique used clean the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac346e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_contain_sentiments=[]\n",
    "def text_preprocessing (FacebookData) :\n",
    "    \n",
    "    FacebookData=remove_redundant_rows(FacebookData) # Redundunt data remove \n",
    "    for row in FacebookData.itertuples(index = True, name ='Pandas'):\n",
    "        text= cleaning_text(getattr(row, \"headline\"))\n",
    "        text=tokenization_lemmatize_stopwording(text)\n",
    "        sentiment=sentiment_scores(text)\n",
    "        pricesentiment=price_prediction(sentiment)\n",
    "        \n",
    "            \n",
    "        list_contain_sentiments.append([getattr(row, \"datetime\"),text,sentiment,pricesentiment])\n",
    "        \n",
    "    return list_contain_sentiments\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "74102bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_contain_sentiments=text_preprocessing(full_df)\n",
    "dataframe=data_frame(list_contain_sentiments)\n",
    "privot_table=sentiment_average_score(dataframe[['Date','Textsentiment','Priceprediction']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "97108175",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "02feee96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-07\n",
      "2021-11-08\n",
      "2021-11-09\n",
      "2021-11-10\n",
      "2021-11-11\n"
     ]
    }
   ],
   "source": [
    "Calculate_price_analysis_dy_by_day(privot_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bb87bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
